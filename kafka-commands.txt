-Detail for the topics command
  bin/kafka-topics.sh

-Creating a topic will all the required arguments
  bin/kafka-topics.sh --zookeeper zookeeper1:2181/kafka --topic test1 --create --partitions 3 --replication-factor 3

-Creating a topic including all of the zookeeper servers (not required)
  bin/kafka-topics.sh --zookeeper zookeeper1:2181,zookeeper2:2181,zookeeper3:2181/kafka --topic test1 --create --partitions 3 --replication-factor 3

-List all topics
  bin/kafka-topics.sh --zookeeper zookeeper1:2181/kafka --list

-Describing a topic
  bin/kafka-topics.sh --zookeeper zookeeper1:2181/kafka --topic test2 --describe

-Delete a topic
  bin/kafka-topics.sh --zookeeper zookeeper1:2181/kafka --topic test2 --delete

-Detail for the producer command
  bin/kafka-console-producer.sh

-Detail for the consumer command
  bin/kafka-console-consumer.sh

-Detail for the consumer groups command
  bin/kafka-consumer-groups.sh

-Start a console producer to topic 'test'
  bin/kafka-console-producer.sh --broker-list kafka1:9092 --topic test

-Add the acks=all flag to your producer
  bin/kafka-console-producer.sh --broker-list kafka1:9092 --topic test --producer-property acks=all

-Create a topic with the console producer (not recommended)
  bin/kafka-console-producer.sh --broker-list kafka1:9092 --topic test4

-List the newly created topic
  bin/kafka-topics.sh --zookeeper zookeeper1:2181/kafka --list

-View the partitions for a topic
  bin/kafka-topics.sh --zookeeper zookeeper1:2181/kafka --topic test5 --describe

-Start a console consumer to a topic
  bin/kafka-console-consumer.sh --bootstrap-server kafka3:9092 --topic test

-Consuming messages from the beginning
  bin/kafka-console-consumer.sh --bootstrap-server kafka3:9092 --topic test --from-beginning

-Start a consumer group for a topic
  bin/kafka-console-consumer.sh --bootstrap-server kafka3:9092 --topic test --group application1

-Start producing new messages to a topic
  bin/kafka-console-producer.sh --broker-list kafka1:9092 --topic test

-Start a consumer group and read messages from the beginning
  bin/kafka-console-consumer.sh --bootstrap-server kafka3:9092 --topic test --group application1 --from-beginning

-List the consumer groups
  bin/kafka-consumer-groups.sh --bootstrap-server kafka3:9092 --list

-Describe a consumer group
  bin/kafka-consumer-groups.sh --bootstrap-server kafka3:9092 --describe --group application1

-Performance test
  ./bin/kafka-producer-perf-test.sh --topic test4 --num-records 10000 -throughput 10 --payload-file randomdatafile.txt --producer-props acks=1 bootstrap.servers=kafka1:9092,kafka3:9092 --payload-delimiter A

***********
PARTITIONS:
***********
Where partitions are stored ?
server.properties (File) -> log.dirs (property)

Eg: /data/kafka
ls /data/kafka
test-0 test-1

cd test-0
ls 
0000000000000000.log (data payload is stored)
0000000000000000.timeindex [ mappings between message offset and physical location 
0000000000000000.index       inside index file ]
0000000000000000.snapshot (internal kafka snapshots)
0000000000000011.log
0000000000000011.timeindex
0000000000000011.index
0000000000000011.snapshot

leader-epoch-checkpoint  (handle leader failures between replicas)

-Output the data from the partition log
  ./bin/kafka-run-class.sh kafka.tools.DumpLogSegments --print-data-log --files /data/kafka/test5-6/00000000000000000000.log

-Rotate the logs
  ./bin/kafka-configs.sh --zookeeper zookeeper1:2181/kafka --alter --entity-type topics --entity-name test --add-config segment.ms=60000
  
-Open a producer to send messages
  ./bin/kafka-console-producer.sh --broker-list kafka1:9092 --topic test
  
-Remove the log rotation setting
  ./bin/kafka-configs.sh --zookeeper zookeeper1:2181/kafka --alter --entity-type topics --entity-name test --delete-config segment.ms

-Create the json file to reassign partitions
  {"topics":
    [{"topic": "test"}],
    "version":1
  }

-Run the command through a dry-run
  ./bin/kafka-reassign-partitions.sh --zookeeper zookeeper1:2181/kafka --generate \
  --topics-to-move-json-file topics.json \
  --broker-list 3,2,1

-Execute the reassignment
  ./bin/kafka-reassign-partitions.sh --zookeeper zookeeper1:2181/kafka --execute \
  --reassignment-json-file plan.json 

-Verify the reassignment completed
  ./bin/kafka-reassign-partitions.sh --zookeeper zookeeper1:2181/kafka --verify \  
  --reassignment-json-file plan.json

-Change the replication factor
  {"partitions":
  [{"topic": "test", "partition": 0,
  "replicas": [
  2,
  1
  ]
  }
  ],
  "version":1
  }

-Execute the replication factor change
  ./bin/kafka-reassign-partitions.sh --zookeeper zookeeper1:2181/kafka --execute \
  --reassignment-json-file replicacount.json

-Describe the topic and see the change
  ./bin/kafka-topics.sh --zookeeper zookeeper1:2181/kafka --topic test --describe
  
-Re-assign the leader replica
  ./bin/kafka-preferred-replica-election.sh --zookeeper zookeeper1:2181/kafka

***********
Reliability
***********
acks = 0 / 1 / all

./bin/kafka-console-producer.sh --broker-list kafka1:9092 --topic test --producer-property acks=all

---------
Security
---------
Authentication of connections to brokers from clients (producers and consumers), other brokers and tools, using either SSL or SASL. 
-Kafka supports the following SASL mechanisms:
  SASL/GSSAPI (Kerberos) - starting at version 0.9.0.0
  SASL/PLAIN - starting at version 0.10.0.0
  SASL/SCRAM-SHA-256 and SASL/SCRAM-SHA-512 - starting at version 0.10.2.0
  SASL/OAUTHBEARER - starting at version 2.0
  
-Java Utility to generate certificate
keytool -keystore server.keystore.jks -alias kafka1 -validity 365 -genkey -keyalg RSA 
  
----------
Data Types
----------


-------------
Kafka Connect
-------------
./bin/connect-standalone.sh config/connect-standalone.properties config/connect-file-source.properties

./bin/connect-standalone.sh config/connect-standalone.properties config/connect-file-source.properties config/connect-file-sink.properties

----------
Topics
----------
# Create a topic if a topic with the same name does NOT exist
bin/kafka-topics.sh --zookeeper zookeeper1:2181/kafka \
--create \
--topic topic-1 \
--replication-factor 1 \
--partitions 3 \
--if-not-exists

# Alter the number of partitions (can only go up)
bin/kafka-topics.sh --zookeeper zookeeper1:2181/kafka \
--alter \
--topic topic-1 \
--partitions 7

# Delete a topic (this is irreversible)
bin/kafka-topics.sh --zookeeper zookeeper1:2181/kafka \
--delete \
--topic topic-1

# List all topics
bin/kafka-topics.sh --zookeeper zookeeper1:2181/kafka \
--list

# Describe all the topics at once
bin/kafka-topics.sh --zookeeper zookeeper1:2181/kafka \
--describe

# Identify any overrides to topics (configs added to the defaults)
bin/kafka-topics.sh --zookeeper zookeeper1:2181/kafka \
--describe \
--topics-with-overrides

# Topics that are not in-sync with all replicas
bin/kafka-topics.sh --zookeeper zookeeper1:2181/kafka \
--describe \
--under-replicated-partitions

# Topics without a leader replica
bin/kafka-topics.sh --zookeeper zookeeper1:2181/kafka \
--describe \
--unavailable-partitions

# Describe the configurations for all topics (only in addition to the defaults)
bin/kafka-configs.sh --zookeeper zookeeper1:2181/kafka \
--describe \
--entity-type topics

# Describe the configurations for a specific topic (defaults will not show)
bin/kafka-configs.sh --zookeeper zookeeper1:2181/kafka \
--describe \
--entity-type topics \
--entity-name topic-1

# Change the topics message retention
bin/kafka-configs.sh --zookeeper zookeeper1:2181/kafka \
--alter \
--entity-type topics \
--entity-name connect-test \
--add-config retention.ms=3600000

# Describe the configurations for all brokers (defaults will not show)
bin/kafka-configs.sh --zookeeper zookeeper1:2181/kafka \
--entity-type brokers \
--entity-default \
--describe

# Describe the configuration for broker 0 (defaults will not show)
bin/kafka-configs.sh --zookeeper zookeeper1:2181/kafka \
--entity-type brokers \
--entity-name 0 \
--describe

# Add a custom config to broker 0 that will change it's log cleaner thread count
bin/kafka-configs.sh --zookeeper zookeeper1:2181/kafka \
--entity-type brokers \
--entity-name 0 \
--alter \
--add-config log.cleaner.threads=2

# Remove all custom configs (not including defaults) from broker 0
bin/kafka-configs.sh --zookeeper zookeeper1:2181/kafka \
--entity-type brokers \
--entity-name 0 \
--alter \
--delete-config log.cleaner.threads

---------------
Consumer Groups
---------------
# List all the consumer groups
bin/kafka-consumer-groups.sh --bootstrap-server kafka1:9092 \
--list

# Describe a specific consumer group
bin/kafka-consumer-groups.sh --bootstrap-server kafka1:9092 \
--describe \
--group application1

# Describe the active members of the group 
bin/kafka-consumer-groups.sh --bootstrap-server kafka1:9092 \
--describe \
--group application1 \
--members

# If the group has active members, get a more verbose output
bin/kafka-consumer-groups.sh --bootstrap-server kafka1:9092 \
--describe \
--group application1 \
--members \
--verbose

# Describe the state of the group
bin/kafka-consumer-groups.sh --bootstrap-server kafka1:9092 \
--describe \
--group application1 \
--state

# Delete a consumer group (only works if there are no active members). 
bin/kafka-consumer-groups.sh --bootstrap-server kafka1:9092 \
--delete \
--group application1

# Delete multiple consumer groups
bin/kafka-consumer-groups.sh --bootstrap-server kafka1:9092 \
--delete \
--group application1 \
--group application2

# Reset offsets for a consumer group
bin/kafka-consumer-groups.sh --bootstrap-server kafka:9092 \
--reset-offsets \
--group application1 \
--topic topic-1 \
--to-latest

------------------
Log Compaction
------------------
-Create a topic with log compaction:
bin/kafka-topics.sh --zookeeper zookeeper1:2181/kafka \
--create \
--topic transaction \
--partitions 1 \
--replication-factor 1 \
--config cleanup.policy=compact \
--config min.cleanable.dirty.ratio=0.001 \
--config segment.ms=5000

-Describe the topic to see the configuration:
bin/kafka-topics.sh --zookeeper zookeeper1:2181/kafka \
--topic transaction \
--describe

-Open a consumer to the topic:
bin/kafka-console-consumer.sh --bootstrap-server kafka1:9092 \
--topic transaction \
--from-beginning \
--property print.key=true \
--property key.separator=,

-Open a producer to write messages to Kafka:
bin/kafka-console-producer.sh --broker-list kafka1:9092 \
--topic transaction \
--property parse.key=true \
--property key.separator=,


